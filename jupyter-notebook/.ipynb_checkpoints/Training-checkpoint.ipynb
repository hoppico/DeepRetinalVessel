{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acute-rocket",
   "metadata": {},
   "source": [
    "# Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "planned-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 17 15:10:13 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.64       Driver Version: 430.64       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 33%   35C    P0    52W / 300W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 18%   32C    P0    55W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "2.3.0-dev20200523\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import os\n",
    "import datetime\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"     #use GPU-0 \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "gpus=tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-processor",
   "metadata": {},
   "source": [
    "## Process and Generate the Training Image Patch 数据预处理与训练图像块生成\n",
    "\n",
    "### setting of dataset path 设置部分\n",
    "\n",
    "- set the parameter and dataset dir (设定数据集的位置以及超参数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "declared-society",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images: 14\n",
      "number of valid images: 6\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "patch_size=48        # patch image size (图像块大小)\n",
    "patch_num=1000        # sample number of one training image  (每张训练图像采样的图像块数量)\n",
    "patch_threshold=25   # threshold for the patch, the smaller threshoold, the less vessel in the patch (采样阈值，数值越小，图像块内的血管面积越小)\n",
    "TRAIN_OR_VAL=0.7\n",
    "dataset_path='/home/ccxing/disk/workbook/Vessel/DRIVE-datasets/'   # modify the dataset_path to your own dir（将dataset_path修改至你自己的路径）\n",
    "\n",
    "train_dir=dataset_path+\"training/\"\n",
    "\n",
    "train_image_dir=train_dir+\"images/\"\n",
    "train_mask_dir=train_dir+\"mask/\"\n",
    "train_groundtruth_dir=train_dir+\"1st_manual/\"\n",
    "train_patch_dir=train_dir+\"patch/\"\n",
    "\n",
    "\n",
    "train_image_path_list=glob(train_image_dir+\"*.tif\")\n",
    "\n",
    "\n",
    "val_image_path_list=random.sample(train_image_path_list,int(len(train_image_path_list)*(1-TRAIN_OR_VAL)))\n",
    "train_image_path_list=[i for i in train_image_path_list if i not in val_image_path_list]\n",
    "\n",
    "print(\"number of training images:\",len(train_image_path_list))\n",
    "print(\"number of valid images:\",len(val_image_path_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-socket",
   "metadata": {},
   "source": [
    "### Image Preprocess （图像预处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inside-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_normalized(imgs,mask):\n",
    "    imgs_normalized = np.empty(imgs.shape)\n",
    "    imgs_std = np.std(imgs)\n",
    "    imgs_mean = np.mean(imgs)\n",
    "    imgs_normalized = (imgs-imgs_mean)/imgs_std\n",
    "    for i in range(imgs.shape[2]):\n",
    "        imgs_normalized[:,:,i] = ((imgs_normalized[:,:,i] - np.min(imgs_normalized[:,:,i])) / (np.max(imgs_normalized[:,:,i])-np.min(imgs_normalized[:,:,i])))*255\n",
    "    return imgs_normalized\n",
    "\n",
    "# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "#adaptive histogram equalization is used. In this, image is divided into small blocks called \"tiles\" (tileSize is 8x8 by default in OpenCV). Then each of these blocks are histogram equalized as usual. So in a small area, histogram would confine to a small region (unless there is noise). If noise is there, it will be amplified. To avoid this, contrast limiting is applied. If any histogram bin is above the specified contrast limit (by default 40 in OpenCV), those pixels are clipped and distributed uniformly to other bins before applying histogram equalization. After equalization, to remove artifacts in tile borders, bilinear interpolation is applied\n",
    "def clahe_equalized(imgs):\n",
    "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "  imgs_equalized = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    imgs_equalized[:,:,i] = clahe.apply(np.array(imgs[:,:,i], dtype = np.uint8))\n",
    "  return imgs_equalized\n",
    "\n",
    "def normalized(imgs):\n",
    "  imgs_normalized =np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    imgs_normalized[:,:,i] =cv2.equalizeHist(imgs[:,:,i])\n",
    "  return imgs_normalized\n",
    "\n",
    "def adjust_gamma(imgs, gamma=1.0):\n",
    "  invGamma = 1.0 / gamma\n",
    "  table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "  # apply gamma correction using the lookup table\n",
    "  new_imgs = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    new_imgs[:,:,i] = cv2.LUT(np.array(imgs[:,:,i], dtype = np.uint8), table)\n",
    "  return new_imgs\n",
    "\n",
    "def preprocess(image,mask):\n",
    "  \n",
    "  assert np.max(mask)==1\n",
    "  image=np.array(image)\n",
    "  image[:,:,0]=image[:,:,0]*mask\n",
    "  image[:,:,1]=image[:,:,1]*mask\n",
    "  image[:,:,2]=image[:,:,2]*mask\n",
    "  \n",
    "  image=restrict_normalized(image,mask)\n",
    "  image=clahe_equalized(image)\n",
    "  image=adjust_gamma(image,1.2)\n",
    "  image=image/255.0\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-cooler",
   "metadata": {},
   "source": [
    "### Generate Image/Mask Patches （图像块生成部分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interracial-stockholm",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate the training patches: 100%|██████████| 14/14 [00:19<00:00,  1.40s/it]\n",
      "Generate the val patches: 100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "def check_coord(x,y,h,w,patch_size):\n",
    "  if x-patch_size/2>0 and x+patch_size/2<h and y-patch_size/2>0 and y+patch_size/2<w:\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "def image2patch(image_path,patch_num,patch_size,training=True,show=True):\n",
    "  image_name=image_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "  image=plt.imread(image_path)\n",
    "\n",
    "  groundtruth=plt.imread(train_groundtruth_dir+image_name+\"_manual1.gif\")\n",
    "  groundtruth=np.where(groundtruth>0,1,0)\n",
    "\n",
    "  mask=plt.imread(train_mask_dir+image_name+\"_training_mask.gif\")\n",
    "  mask=np.where(mask>0,1,0)\n",
    "  \n",
    "  image=preprocess(image,mask)\n",
    "  #image_binary=0.8*image[:,:,1]+0.2*image[:,:,2]  \n",
    "\n",
    "  image_show=image.copy()\n",
    "  groundtruth_show=np.zeros_like(image)\n",
    "  groundtruth_show[:,:,0]=groundtruth.copy()\n",
    "  groundtruth_show[:,:,1]=groundtruth.copy()\n",
    "  groundtruth_show[:,:,2]=groundtruth.copy()\n",
    "\n",
    "  sample_count=0\n",
    "  sample_index=0\n",
    "  \n",
    "  sample_point=np.where(groundtruth==1)     # generate sample point (生成采样中心点)\n",
    "\n",
    "  state = np.random.get_state()      # shuffle the coord (打乱顺序，模拟随机采样)\n",
    "  np.random.shuffle(sample_point[0])\n",
    "  np.random.set_state(state)\n",
    "  np.random.shuffle(sample_point[1])\n",
    "\n",
    "  patch_image_list=[]\n",
    "  patch_groundtruth_list=[]\n",
    "\n",
    "  while sample_count<patch_num and sample_index<len(sample_point[0]):\n",
    "    x,y=sample_point[0][sample_index],sample_point[1][sample_index]\n",
    "    if check_coord(x,y,image.shape[0],image.shape[1],patch_size):\n",
    "      if np.sum(mask[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2])>patch_threshold:     #select according to the threshold\n",
    "       \n",
    "        patch_image_binary=image[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2,:]   # patch image\n",
    "        patch_groundtruth=groundtruth[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2]       # patch mask\n",
    "        #patch_image_binary=np.asarray(0.25*patch_image[:,:,2]+0.75*patch_image[:,:,1])         # B*0.25+G*0.75, which enhance the vessel (增强血管的对比度)\n",
    "        patch_groundtruth=np.where(patch_groundtruth>0,255,0)\n",
    "    \n",
    "        #patch_image_binary =cv2.equalizeHist((patch_image_binary*255.0).astype(np.uint8))/255.0\n",
    "        \n",
    "        patch_image_list.append(patch_image_binary)    # patch image\n",
    "        patch_groundtruth_list.append(patch_groundtruth)             # patch mask\n",
    "        if show:\n",
    "          cv2.rectangle(image_show, (y-patch_size//2,x-patch_size//2,), (y+patch_size//2,x+patch_size//2), (0,1,0), 2)  #draw the illustration\n",
    "          cv2.rectangle(groundtruth_show, (y-patch_size//2,x-patch_size//2,), (y+patch_size//2,x+patch_size//2), (0,1,0), 2)\n",
    "        sample_count+=1\n",
    "    \n",
    "    if show:                                 # visualize the sample process(可视化采样过程，会很慢！)\n",
    "      plt.figure(figsize=(15,15))\n",
    "      plt.title(\"processing: %s\"%image_name)\n",
    "      plt.subplot(121)\n",
    "      plt.imshow(image_show,cmap=plt.cm.gray)   # processd image\n",
    "      plt.subplot(122)\n",
    "      plt.imshow(groundtruth_show,cmap=plt.cm.gray)  #groundtruth of the image, patch is showed as the green square (绿色的方框表示采样的图像块)\n",
    "      plt.show()\n",
    "      display.clear_output(wait=True)\n",
    "    sample_index+=1\n",
    "\n",
    "  for i in range(len(patch_image_list)):\n",
    "    if training==True:\n",
    "        plt.imsave(train_patch_dir+image_name+\"-\"+str(i)+\"-img.jpg\",patch_image_list[i])\n",
    "        #print(patch_mask_list[i])\n",
    "        plt.imsave(train_patch_dir+image_name+\"-\"+str(i)+\"-groundtruth.jpg\",(patch_groundtruth_list[i]/225.0).astype(np.uint8),cmap = plt.cm.gray)\n",
    "    else:\n",
    "        plt.imsave(train_patch_dir+image_name+\"_\"+str(i)+\"_val_img.jpg\",patch_image_list[i])\n",
    "        #print(patch_mask_list[i])\n",
    "        plt.imsave(train_patch_dir+image_name+\"_\"+str(i)+\"_val_groundtruth.jpg\",(patch_groundtruth_list[i]/225.0).astype(np.uint8),cmap = plt.cm.gray)\n",
    "\n",
    "# delete original patch images (删除已有的图像块数据)\n",
    "if not os.path.exists(train_patch_dir):\n",
    "  os.mkdir(train_patch_dir)\n",
    "else:\n",
    "  shutil.rmtree(train_patch_dir)\n",
    "  os.mkdir(train_patch_dir)    \n",
    "\n",
    "    \n",
    "# generate patch images (生成图像块数据)\n",
    "for i in tqdm(range(len(train_image_path_list)),desc=\"Generate the training patches: \"):\n",
    "  image2patch(train_image_path_list[i],patch_num,patch_size,training=True,show=False)  # set show=True to visualize the sample process, which is much slower than show=False\n",
    "\n",
    "for i in tqdm(range(len(val_image_path_list)),desc=\"Generate the val patches: \"):\n",
    "  image2patch(val_image_path_list[i],patch_num,patch_size,training=False,show=False)  # set show=True to visualize the sample process, which is much slower than show=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-conviction",
   "metadata": {},
   "source": [
    "## [Part-II] Model Defination 定义U-net模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prescription-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import AveragePooling2D,Conv2DTranspose,Input,Add,Conv2D, BatchNormalization,LeakyReLU, Activation, MaxPool2D, Dropout, Flatten, Dense,UpSampling2D,Concatenate,Softmax\n",
    "\n",
    "# define the model under eager mode\n",
    "\n",
    "class LinearTransform(tf.keras.Model):\n",
    "  def __init__(self, name=\"LinearTransform\"):\n",
    "    super(LinearTransform, self).__init__(self,name=name)\n",
    "\n",
    "    self.conv_r=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "    self.conv_g=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "    self.conv_b=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "\n",
    "    self.pool_rc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "    self.pool_gc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "    self.pool_bc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "        \n",
    "    self.bn=BatchNormalization()\n",
    "    self.sigmoid=Activation('sigmoid')\n",
    "    self.softmax=Activation('softmax')\n",
    "\n",
    "  def call(self, input,training=True):\n",
    "    r,g,b=input[:,:,:,0:1],input[:,:,:,1:2],input[:,:,:,2:3]\n",
    "\n",
    "    rs=self.conv_r(r)\n",
    "    gs=self.conv_g(g)\n",
    "    bs=self.conv_r(b)\n",
    "\n",
    "    rc=tf.reshape(self.pool_rc(rs),[-1,1])\n",
    "    gc=tf.reshape(self.pool_gc(gs),[-1,1])\n",
    "    bc=tf.reshape(self.pool_bc(bs),[-1,1])\n",
    "\n",
    "    merge=Concatenate(axis=-1)([rc,gc,bc])\n",
    "    merge=tf.expand_dims(merge,axis=1)\n",
    "    merge=tf.expand_dims(merge,axis=1)\n",
    "    merge=self.softmax(merge)\n",
    "    merge=tf.repeat(merge,repeats=48,axis=2)\n",
    "    merge=tf.repeat(merge,repeats=48,axis=1)\n",
    "\n",
    "    r=r*(1+self.sigmoid(rs))\n",
    "    g=g*(1+self.sigmoid(gs))\n",
    "    b=b*(1+self.sigmoid(bs))\n",
    "\n",
    "    output=self.bn(merge[:,:,:,0:1]*r+merge[:,:,:,1:2]*g+merge[:,:,:,2:3]*b,training=training)\n",
    "    return output\n",
    "\n",
    "class ResBlock(tf.keras.Model):\n",
    "  def __init__(self,out_ch,residual_path=False,stride=1):\n",
    "    super(ResBlock,self).__init__(self)\n",
    "    self.residual_path=residual_path\n",
    "        \n",
    "    self.conv1=Conv2D(out_ch,kernel_size=3,strides=stride,padding='same', use_bias=False,data_format=\"channels_last\")\n",
    "    self.bn1=BatchNormalization()\n",
    "    self.relu1=LeakyReLU()#Activation('leaky_relu')\n",
    "        \n",
    "    self.conv2=Conv2D(out_ch,kernel_size=3,strides=1,padding='same', use_bias=False,data_format=\"channels_last\")\n",
    "    self.bn2=BatchNormalization()\n",
    "        \n",
    "    if residual_path:\n",
    "      self.conv_shortcut=Conv2D(out_ch,kernel_size=1,strides=stride,padding='same',use_bias=False)\n",
    "      self.bn_shortcut=BatchNormalization()\n",
    "        \n",
    "    self.relu2=LeakyReLU()#Activation('leaky_relu')\n",
    "        \n",
    "  def call(self,x,training=True):\n",
    "    xs=self.relu1(self.bn1(self.conv1(x),training=training))\n",
    "    xs=self.bn2(self.conv2(xs),training=training)\n",
    "\n",
    "    if self.residual_path:\n",
    "      x=self.bn_shortcut(self.conv_shortcut(x),training=training)\n",
    "    #print(x.shape,xs.shape)\n",
    "    xs=x+xs\n",
    "    return self.relu2(xs)\n",
    "\n",
    "\n",
    "class Unet(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Unet,self).__init__(self)\n",
    "    self.conv_init=LinearTransform()\n",
    "    self.resinit=ResBlock(16,residual_path=True)\n",
    "    self.up_sample=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resup=ResBlock(32,residual_path=True)\n",
    "    \n",
    "    self.pool1=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock_down1=ResBlock(64,residual_path=True)\n",
    "    self.resblock_down11=ResBlock(64,residual_path=False)\n",
    "    self.pool2=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock_down2=ResBlock(128,residual_path=True)\n",
    "    self.resblock_down21=ResBlock(128,residual_path=False)\n",
    "    self.pool3=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock_down3=ResBlock(256,residual_path=True)\n",
    "    self.resblock_down31=ResBlock(256,residual_path=False)\n",
    "    self.pool4=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock=ResBlock(512,residual_path=True)\n",
    "\n",
    "    self.unpool3=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock_up3=ResBlock(256,residual_path=True)\n",
    "    self.resblock_up31=ResBlock(256,residual_path=False)\n",
    "\n",
    "    self.unpool2=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock_up2=ResBlock(128,residual_path=True)\n",
    "    self.resblock_up21=ResBlock(128,residual_path=False)\n",
    "\n",
    "    self.unpool1=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock_up1=ResBlock(64,residual_path=True)\n",
    "    \n",
    "    self.unpool_final=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock2=ResBlock(32,residual_path=True)\n",
    "    \n",
    "    self.pool_final=MaxPool2D(pool_size=(2,2))\n",
    "    self.resfinal=ResBlock(32)\n",
    "    \n",
    "    self.conv_final=Conv2D(1,kernel_size=1,strides=1,padding='same',use_bias=False)\n",
    "    self.bn_final=BatchNormalization()\n",
    "    self.act=Activation('sigmoid')\n",
    "\n",
    "  def call(self,x,training=True):\n",
    "    x_linear=self.conv_init(x,training=training)\n",
    "    x=self.resinit(x_linear,training=training)\n",
    "    x=self.up_sample(x)\n",
    "    x=self.resup(x,training=training)\n",
    "    \n",
    "    stage1=self.pool1(x)\n",
    "    stage1=self.resblock_down1(stage1,training=training)\n",
    "    stage1=self.resblock_down11(stage1,training=training)\n",
    "\n",
    "    stage2=self.pool2(stage1)\n",
    "    stage2=self.resblock_down2(stage2,training=training)\n",
    "    stage2=self.resblock_down21(stage2,training=training)\n",
    "\n",
    "    stage3=self.pool3(stage2)\n",
    "    stage3=self.resblock_down3(stage3,training=training)\n",
    "    stage3=self.resblock_down31(stage3,training=training)\n",
    "\n",
    "    stage4=self.pool4(stage3)\n",
    "    stage4=self.resblock(stage4,training=training)\n",
    "\n",
    "    stage3=Concatenate(axis=3)([stage3,self.unpool3(stage4)])\n",
    "    stage3=self.resblock_up3(stage3,training=training)\n",
    "    stage3=self.resblock_up31(stage3,training=training)\n",
    "\n",
    "    stage2=Concatenate(axis=3)([stage2,self.unpool2(stage3)])\n",
    "    stage2=self.resblock_up2(stage2,training=training)\n",
    "    stage2=self.resblock_up21(stage2,training=training)\n",
    "\n",
    "    stage1=Concatenate(axis=3)([stage1,self.unpool1(stage2)])\n",
    "    stage1=self.resblock_up1(stage1,training=training)\n",
    "    \n",
    "    x=Concatenate(axis=3)([x,self.unpool_final(stage1)])\n",
    "    x=self.resblock2(x,training=training)\n",
    "    \n",
    "    x=self.pool_final(x)\n",
    "    x=self.resfinal(x,training=training)\n",
    "    \n",
    "    seg_result=self.act(self.bn_final(self.conv_final(x),training=training))\n",
    "    \n",
    "    return x_linear,seg_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-somerset",
   "metadata": {},
   "source": [
    "## [Part-III] Training Model 训练模型\n",
    "\n",
    "### setting part （设置超参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "organic-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=200\n",
    "VAL_TIME=2\n",
    "LR=0.0003\n",
    "BATCH_SIZE=64\n",
    "\n",
    "checkpoint_path=dataset_path+\"ckpt/\"\n",
    "log_path=dataset_path+\"logs/\"\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "  os.mkdir(checkpoint_path)\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "  os.mkdir(log_path)\n",
    "\n",
    "# use tensorboard to visualize the loss,acc,... (使用tensorboard观察各类指标变化)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-surgeon",
   "metadata": {},
   "source": [
    "### Training/Valid DataLoader (加载训练/测试数据)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "settled-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000 14000\n",
      "['/home/ccxing/disk/workbook/Vessel/DRIVE-datasets/training/patch/28-132-img.jpg', '/home/ccxing/disk/workbook/Vessel/DRIVE-datasets/training/patch/33-781-img.jpg']\n",
      "['/home/ccxing/disk/workbook/Vessel/DRIVE-datasets/training/patch/28-132-groundtruth.jpg', '/home/ccxing/disk/workbook/Vessel/DRIVE-datasets/training/patch/33-781-groundtruth.jpg']\n",
      "['/home/ccxing/disk/workbook/Vessel/DRIVE-datasets/training/patch/21_0_val_img.jpg', '/home/ccxing/disk/workbook/Vessel/DRIVE-datasets/training/patch/21_100_val_img.jpg']\n",
      "['/home/ccxing/disk/workbook/Vessel/DRIVE-datasets/training/patch/21_0_val_groundtruth.jpg', '/home/ccxing/disk/workbook/Vessel/DRIVE-datasets/training/patch/21_100_val_groundtruth.jpg']\n"
     ]
    }
   ],
   "source": [
    "def load_image_groundtruth(img_path,groundtruth_path):\n",
    "  img=tf.io.read_file(img_path)\n",
    "  img=tf.image.decode_jpeg(img,channels=3)\n",
    "  img=tf.image.resize(img,[patch_size,patch_size])\n",
    "\n",
    "  groundtruth=tf.io.read_file(groundtruth_path)\n",
    "  groundtruth=tf.image.decode_jpeg(groundtruth,channels=1)\n",
    "  \n",
    "  # data argument (数据增强部分)\n",
    "  if random.uniform(0,1)>=0.5:\n",
    "    img=tf.image.flip_left_right(img)\n",
    "    groundtruth=tf.image.flip_left_right(groundtruth)\n",
    "\n",
    "#   if random.uniform(0,1)>=0.5:\n",
    "#     seeds=random.uniform(0,1)\n",
    "#     img=tf.image.central_crop(img,seeds)\n",
    "#     groundtruth=tf.image.central_crop(groundtruth,seeds)\n",
    "\n",
    "  img=tf.image.resize(img,[patch_size,patch_size])\n",
    "  groundtruth=tf.image.resize(groundtruth,[patch_size,patch_size])\n",
    "    \n",
    "  img/=255.0\n",
    "  groundtruth=(groundtruth+40)/255.0\n",
    "  groundtruth=tf.cast(groundtruth,dtype=tf.uint8)\n",
    "\n",
    "  return img,groundtruth\n",
    "\n",
    "\n",
    "train_patch_img_path_list=sorted(glob(train_patch_dir+\"*-*-img.jpg\"))\n",
    "train_patch_groundtruth_path_list=sorted(glob(train_patch_dir+\"*-*-groundtruth.jpg\"))\n",
    "train_patch_img_path_list,train_patch_groundtruth_path_list=shuffle(train_patch_img_path_list,train_patch_groundtruth_path_list,random_state=0)\n",
    "\n",
    "# make sure that img-list and mask-list is in order (确保打乱后的image-mask还是对应的) \n",
    "print(len(train_patch_img_path_list),len(train_patch_groundtruth_path_list))\n",
    "print(train_patch_img_path_list[:2])\n",
    "print(train_patch_groundtruth_path_list[:2])\n",
    "\n",
    "val_patch_img_path_list=sorted(glob(train_patch_dir+\"*_*_val_img.jpg\"))\n",
    "val_patch_groundtruth_path_list=sorted(glob(train_patch_dir+\"*_*_val_groundtruth.jpg\"))\n",
    "\n",
    "print(val_patch_img_path_list[:2])\n",
    "print(val_patch_groundtruth_path_list[:2])\n",
    "\n",
    "# Training Dataloader\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((train_patch_img_path_list,train_patch_groundtruth_path_list))\n",
    "train_dataset=train_dataset.map(load_image_groundtruth,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1300).prefetch(BATCH_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# VAL Dataloader\n",
    "val_dataset=tf.data.Dataset.from_tensor_slices((val_patch_img_path_list,val_patch_groundtruth_path_list))\n",
    "val_dataset=val_dataset.map(load_image_groundtruth,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset =val_dataset.shuffle(buffer_size=1300).prefetch(BATCH_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-scanning",
   "metadata": {},
   "source": [
    "### Load and Compile the Model (加载并编译模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "received-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Unet()\n",
    "\n",
    "# Learning rate and optimizer （学习率调整和优化器）\n",
    "cosine_decay = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=LR, first_decay_steps=12000,t_mul=1000,m_mul=0.5,alpha=1e-5)\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=cosine_decay)\n",
    "\n",
    "# loss function （损失函数）\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "# metric record （性能指标记录器）\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_acc=tf.keras.metrics.Mean(name='train_acc')\n",
    "current_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_acc=tf.keras.metrics.Mean(name='val_acc')\n",
    "val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')\n",
    "\n",
    "# checkpoint （模型存档管理器）\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "#ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "#ckpt.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
    "\n",
    "# tensorboard writer （Tensorboard记录器）\n",
    "log_dir=log_path+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_writer = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-extent",
   "metadata": {},
   "source": [
    "### Dice Loss & Dice Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outstanding-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true,y_pred,smooth=1.):\n",
    "  y_true=tf.cast(y_true,dtype=tf.float32)\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred_f = K.flatten(y_pred)\n",
    "  intersection = K.sum(y_true_f * y_pred_f)\n",
    "  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true,y_pred):\n",
    "  return (1-dice(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-wells",
   "metadata": {},
   "source": [
    "### Traing Step & Valid Step\n",
    "\n",
    "training function and validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "southern-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step(step,patch,groundtruth):\n",
    "  with tf.GradientTape() as tape:\n",
    "        \n",
    "    linear,pred_seg=model(patch,training=True)\n",
    "    losses = dice_loss(groundtruth, pred_seg)\n",
    "    \n",
    "  # calculate the gradient （求梯度）\n",
    "  grads = tape.gradient(losses, model.trainable_variables)\n",
    "  # bp (反向传播) \n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  # record the training loss and accuracy (记录loss和准确率)\n",
    "  train_loss.update_state(losses)\n",
    "  train_acc.update_state(dice(groundtruth, pred_seg))\n",
    "\n",
    "\n",
    "\n",
    "def val_step(step,patch,groundtruth):\n",
    " \n",
    "  linear,pred_seg=model(patch,training=False)\n",
    "  losses = dice_loss(groundtruth, pred_seg)\n",
    "    \n",
    "  # record the val loss and accuracy (记录loss和准确率)\n",
    "  val_loss.update_state(losses)\n",
    "  val_acc.update_state(dice(groundtruth, pred_seg))\n",
    "  \n",
    "  tf.summary.image(\"image\",patch,step=step)\n",
    "  tf.summary.image(\"image transform\",linear,step=step)\n",
    "  tf.summary.image(\"groundtruth\",groundtruth*255,step=step)\n",
    "  tf.summary.image(\"pred\",pred_seg,step=step)\n",
    "  log_writer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-location",
   "metadata": {},
   "source": [
    "### Main Function of Training (训练主程序)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_step=0\n",
    "last_val_loss=2e10\n",
    "with log_writer.as_default():\n",
    "  for epoch in range(EPOCHS):\n",
    "    # renew the recorder （重置记录项）\n",
    "    train_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    val_acc.reset_states()\n",
    "  \n",
    "    # training （训练部分）\n",
    "    for tstep, (patch,groundtruth) in enumerate(train_dataset):\n",
    "      train_step(lr_step,patch,groundtruth)\n",
    "    \n",
    "      tf.summary.scalar(\"learning_rate\", optimizer._decayed_lr(tf.float32).numpy(), step=lr_step)\n",
    "      print('\\repoch {}, batch {}, loss:{:.4f}, dice:{:.4f}'.format(epoch + 1, tstep, train_loss.result(), train_acc.result()),end=\"\")\n",
    "      lr_step+=1\n",
    "\n",
    "    if (epoch + 1) % VAL_TIME == 0:\n",
    "      #valid (验证部分)\n",
    "      for vstep, (patch,groundtruth) in enumerate(val_dataset):\n",
    "            \n",
    "        val_step(lr_step,patch,groundtruth)\n",
    "        \n",
    "      print('\\repoch {}, batch {}, train_loss:{:.4f}, train_dice:{:.4f}, val_loss:{:.4f}, val_dice:{:.4f}'.format(epoch + 1, vstep, train_loss.result(), train_acc.result(),val_loss.result(), val_acc.result()),end=\"\")\n",
    "      tf.summary.scalar(\"val_loss\", val_loss.result(), step=epoch)\n",
    "      tf.summary.scalar(\"val_acc\", val_acc.result(), step=epoch)\n",
    "    \n",
    "      if val_loss.result()<last_val_loss:\n",
    "        ckpt.save(checkpoint_path)\n",
    "        last_val_loss=val_loss.result()\n",
    "    print(\"\")\n",
    "    tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch)\n",
    "    tf.summary.scalar(\"train_acc\", train_acc.result(), step=epoch)\n",
    "    log_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-fence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
